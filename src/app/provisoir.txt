'use client';

import {
  Mic,
  Volume2,
  VolumeX,
  Upload,
  LogOut,
  Sun,
  Moon,
} from 'lucide-react';
import Image from 'next/image';
import { useState, useRef, useEffect } from 'react';
import { createClientComponentClient } from '@supabase/auth-helpers-nextjs';
import { useTheme } from 'next-themes';

// Petit type local pour l'événement de MediaRecorder
type DataAvailableEvent = { data: Blob };

// ➕ Helper pour retirer le gras Markdown (**…**)
const stripMdEmphasis = (s: string) => s.replace(/\*\*(.*?)\*\*/g, '$1');

// ✅ Typage propre pour webkitAudioContext
declare global {
  interface Window {
    webkitAudioContext?: typeof AudioContext;
  }
}

// ✅ Helpers storage pour éviter erreurs dans iframe/Safari
const safeStorage = {
  get: (k: string) => {
    try {
      if (typeof window === 'undefined' || !window.sessionStorage) return null;
      return window.sessionStorage.getItem(k);
    } catch {
      return null;
    }
  },
  set: (k: string, v: string) => {
    try {
      if (typeof window === 'undefined' || !window.sessionStorage) return;
      window.sessionStorage.setItem(k, v);
    } catch {}
  },
  remove: (k: string) => {
    try {
      if (typeof window === 'undefined' || !window.sessionStorage) return;
      window.sessionStorage.removeItem(k);
    } catch {}
  },
};

// ✅ Composant principal
export default function Home() {
  const [messages, setMessages] = useState<string[]>([]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);
  const [recording, setRecording] = useState(false);
  const [isSpeakerOn, setIsSpeakerOn] = useState(false);
  const [audioUnlocked, setAudioUnlocked] = useState(false);
  const [voiceLevel, setVoiceLevel] = useState(0);
  const [isAuthed, setIsAuthed] = useState<boolean | null>(null);
  const [mountedTheme, setMountedTheme] = useState(false);

  const supabase = createClientComponentClient();
  const { theme, setTheme } = useTheme();

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const audioCtxRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const dataArrayRef = useRef<Uint8Array | null>(null);
  const rafIdRef = useRef<number | null>(null);
  const userIsSpeakingRef = useRef(false);
  const lastVoiceTsRef = useRef<number>(0);
  const currentAudioRef = useRef<HTMLAudioElement | null>(null);
  const isSpeakingRef = useRef<boolean>(false);
  const bottomRef = useRef<HTMLDivElement>(null);
  const fileInputRef = useRef<HTMLInputElement | null>(null);

  // ✅ Récupération session via ?code=…
  useEffect(() => {
    if (typeof window === 'undefined') return;
    const url = new URL(window.location.href);
    const code = url.searchParams.get('code');
    if (!code) return;

    supabase.auth
      .exchangeCodeForSession(code)
      .then(() => {
        url.searchParams.delete('code');
        url.searchParams.delete('state');
        window.history.replaceState({}, '', url.toString());
      })
      .catch(() => {});
  }, [supabase]);

  // ✅ Auth state
  useEffect(() => {
    let mounted = true;
    supabase.auth
      .getUser()
      .then(({ data }) => mounted && setIsAuthed(!!data.user))
      .catch(() => mounted && setIsAuthed(false));
    const { data: listener } = supabase.auth.onAuthStateChange((_e, session) => {
      setIsAuthed(!!session?.user);
    });
    return () => {
      mounted = false;
      listener.subscription.unsubscribe();
    };
  }, [supabase]);

  useEffect(() => setMountedTheme(true), []);

  useEffect(() => {
    try {
      const saved = safeStorage.get('chatMessages');
      if (saved) {
        const parsed = JSON.parse(saved);
        if (Array.isArray(parsed)) setMessages(parsed);
      }
    } catch {}
  }, []);

  useEffect(() => {
    try {
      safeStorage.set('chatMessages', JSON.stringify(messages));
    } catch {}
    bottomRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  const handleGoogleLogin = async () => {
    const origin =
      typeof window !== 'undefined' && window.location?.origin
        ? window.location.origin
        : undefined;
    await supabase.auth.signInWithOAuth({
      provider: 'google',
      options: {
        redirectTo: origin,
        queryParams: { prompt: 'consent', access_type: 'offline' },
      },
    });
  };

  const handleLogout = async () => {
    try {
      await stopRecordingAndCleanup();
      await supabase.auth.signOut({ scope: 'global' });
      safeStorage.remove('chatMessages');
      setMessages([]);
      setIsAuthed(false);
      if (typeof window !== 'undefined') window.location.assign('/');
    } catch (e) {
      console.error('Erreur logout:', e);
    }
  };

  const handleSubmit = async (customInput?: string) => {
    const promptToSend = customInput ?? input;
    if (!promptToSend.trim()) return;
    const userMessage = `🧠 ${promptToSend}`;
    setMessages((prev) => [...prev, userMessage]);
    setInput('');
    setLoading(true);

    try {
      const {
        data: { session },
      } = await supabase.auth.getSession();
      const token = session?.access_token;
      const response = await fetch('/api/ask', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          ...(token ? { Authorization: `Bearer ${token}` } : {}),
        },
        body: JSON.stringify({ message: promptToSend }),
      });
      const data: { message?: string } = await response.json();

      if (response.ok && data.message) {
        setMessages((prev) => [...prev, '🤖 ']);
        const replyText = stripMdEmphasis(data.message);
        let i = 0;
        const interval = setInterval(() => {
          setMessages((prev) => {
            const updated = prev.slice(0, -1);
            return [...updated, '🤖 ' + replyText.slice(0, i)];
          });
          i++;
          if (i > replyText.length) clearInterval(interval);
        }, 30);
        await stopRecordingAndCleanup();
        speak(replyText);
      } else {
        setMessages((prev) => [...prev, '❌ Réponse invalide']);
      }
    } catch (error) {
      console.error(error);
      setMessages((prev) => [...prev, '⚠️ Une erreur est survenue']);
    }

    setLoading(false);
  };

  const speak = async (text: string) => {
    if (!isSpeakerOn || !text?.trim()) return;
    try {
      if (!audioUnlocked) unlockAudioContext();

      if (currentAudioRef.current) {
        try {
          currentAudioRef.current.pause();
        } catch {}
        currentAudioRef.current.src = '';
        currentAudioRef.current = null;
      }

      const res = await fetch('/api/voice', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text }),
      });

      if (!res.ok) {
        console.error('Erreur API ElevenLabs:', await res.text().catch(() => ''));
        return;
      }

      const blob = await res.blob();
      const audioUrl = URL.createObjectURL(blob);
      const audio = new Audio(audioUrl);
      currentAudioRef.current = audio;
      isSpeakingRef.current = true;

      audio.onended = () => {
        if (currentAudioRef.current === audio) currentAudioRef.current = null;
        isSpeakingRef.current = false;
        URL.revokeObjectURL(audioUrl);
      };
      audio.onerror = () => {
        isSpeakingRef.current = false;
      };

      await audio.play().catch((e) => {
        console.error('Lecture audio bloquée/erreur:', e);
      });
    } catch (err) {
      console.error('Erreur audio :', err);
      isSpeakingRef.current = false;
    }
  };

  const unlockAudioContext = () => {
    if (audioUnlocked) return;
    const audio = new Audio();
    audio.src =
      'data:audio/wav;base64,UklGRiQAAABXQVZFZm10IBAAAAABAAEAESsAACJWAAACABAAZGF0YQAAAAA=';
    audio.play().catch(() => {});
    setAudioUnlocked(true);
  };

  const stopRecordingAndCleanup = async () => {
    try {
      if (mediaRecorderRef.current?.state === 'recording') {
        mediaRecorderRef.current.stop();
      }
    } catch {}

    if (streamRef.current) {
      streamRef.current.getTracks().forEach((t) => t.stop());
      streamRef.current = null;
    }

    if (rafIdRef.current) {
      cancelAnimationFrame(rafIdRef.current);
      rafIdRef.current = null;
    }

    if (audioCtxRef.current) {
      try {
        await audioCtxRef.current.close();
      } catch {}
      audioCtxRef.current = null;
    }

    analyserRef.current = null;
    dataArrayRef.current = null;
    userIsSpeakingRef.current = false;
    setVoiceLevel(0);
    setRecording(false);
  };

  // 👇 Tu peux maintenant ajouter ici le code du Voice Input, Image Upload, UI <main>, etc.
  return <div className="text-white p-10 text-center">✅ Composant Home fonctionnel. UI à compléter.</div>;
}
