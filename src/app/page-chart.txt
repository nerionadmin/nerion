'use client';
import { Mic, Volume2, Upload, LogOut, Activity } from 'lucide-react';
import Image from 'next/image';
import { useState, useRef, useEffect } from 'react';
import { createClientComponentClient } from '@supabase/auth-helpers-nextjs';

// Petit type local pour l'√©v√©nement de MediaRecorder
type DataAvailableEvent = { data: Blob };

// ‚ûï Helper pour retirer le gras Markdown (**‚Ä¶**)
const stripMdEmphasis = (s: string) => s.replace(/\*\*(.*?)\*\*/g, '$1');

// ‚úÖ Typage propre pour webkitAudioContext
declare global {
  interface Window {
    webkitAudioContext?: typeof AudioContext;
  }
}

export default function Home() {
  const [messages, setMessages] = useState<string[]>([]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);

  // ‚ö†Ô∏è retir√©: isSpeakerOn (on fusionne micro+HP dans un seul bouton)
  const [audioUnlocked, setAudioUnlocked] = useState(false);

  // üéõÔ∏è UI: niveau de voix (0 ‚Üí 1) pour afficher des vibrations dans la barre de recherche
  const [voiceLevel, setVoiceLevel] = useState(0);

  // √âtats/refs pour la capture audio + VAD
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const audioCtxRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const dataArrayRef = useRef<Uint8Array | null>(null);
  const rafIdRef = useRef<number | null>(null);
  const userIsSpeakingRef = useRef(false);
  const lastVoiceTsRef = useRef<number>(0);

  const bottomRef = useRef<HTMLDivElement>(null);

  // üîä Lecture audio fiable (une seule instance)
  const currentAudioRef = useRef<HTMLAudioElement | null>(null);
  const isSpeakingRef = useRef<boolean>(false);

  // ‚ñ∂Ô∏è Nouveau: √©tat vocal combin√© (ic√¥ne uniquement)
  const [voiceState, setVoiceState] = useState<'idle' | 'listening' | 'speaking'>('idle');
  // ‚ñ∂Ô∏è Nouveau: r√©f on/off du mode vocal (remplace l'ancien isSpeakerOn)
  const voiceEnabledRef = useRef<boolean>(false);
  // ‚ñ∂Ô∏è Petit helper
  const canStartRecording = () => !recording && !loading && !isSpeakingRef.current;

  // ‚ö†Ô∏è retir√©: recording set via hook existant
  const [recording, setRecording] = useState(false);

  // ‚è±Ô∏è cleanup de l'animation "typing"
  const typingIntervalRef = useRef<number | null>(null);

  const USER_ID = 'demo_user_1'; // provisoire

  // ‚õîÔ∏è Gate d‚Äôauth
  const supabase = createClientComponentClient();
  // ‚¨áÔ∏è √âchange ?code=... -> session (cookies sb-...) ‚Äî version corrig√©e
  useEffect(() => {
    if (typeof window === "undefined") return;
    const url = new URL(window.location.href);
    const code = url.searchParams.get("code");
    if (!code) return;

    supabase.auth.exchangeCodeForSession(code)
      .then(() => {
        // on nettoie l‚ÄôURL (retire code/state pour √©viter de relancer l‚Äô√©change)
        url.searchParams.delete("code");
        url.searchParams.delete("state");
        window.history.replaceState({}, "", url.toString());
      })
      .catch(() => {});
  }, [supabase]);
  // ‚¨ÜÔ∏è AJOUT UNIQUE

  const [isAuthed, setIsAuthed] = useState<boolean | null>(null);
  useEffect(() => {
    let mounted = true;
    supabase.auth
      .getUser()
      .then(({ data }) => mounted && setIsAuthed(!!data.user))
      .catch(() => mounted && setIsAuthed(false));
    const { data: listener } = supabase.auth.onAuthStateChange((_e, session) => {
      setIsAuthed(!!session?.user);
    });
    return () => {
      mounted = false;
      listener.subscription.unsubscribe();
    };
  }, [supabase]);

  // üîΩüîΩüîΩ UNIQUE MODIF ICI : handler du bouton Google (ajout queryParams)
  const handleGoogleLogin = async () => {
    const origin =
      typeof window !== 'undefined' && window.location?.origin
        ? window.location.origin
        : undefined;

    await supabase.auth.signInWithOAuth({
      provider: 'google',
      options: {
        redirectTo: origin,
        queryParams: {
          prompt: 'consent',
          access_type: 'offline',
        },
      },
    });
  };
  // üîºüîºüîº UNIQUE MODIF ICI

  // ‚úÖ Logout : coupe audio + vide l'UI + purge la session locale
  const handleLogout = async () => {
    try {
      await stopRecordingAndCleanup(); // coupe micro/lectures si besoin
      stopTTS(); // coupe la voix en cours si besoin
      voiceEnabledRef.current = false;
      setVoiceState('idle');

      await supabase.auth.signOut();
      sessionStorage.removeItem("chatMessages"); // supprime l'historique persistant c√¥t√© navigateur
      setMessages([]);                            // vide l'affichage du chat
      setIsAuthed(false);
    } catch (e) {
      console.error('Erreur logout:', e);
    }
  };

  const handleSubmit = async (customInput?: string) => {
    const promptToSend = customInput ?? input;
    if (!promptToSend.trim()) return;

    const userMessage = `üß† ${promptToSend}`;
    setMessages((prev) => [...prev, userMessage]);
    setInput('');
    setLoading(true);

    try {
      // ********** CORRECTION: envoi du Bearer token, plus de userId dans le body **********
      const { data: { session } } = await supabase.auth.getSession();
      const token = session?.access_token;

      const response = await fetch('/api/ask', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          ...(token ? { Authorization: `Bearer ${token}` } : {}),
        },
        body: JSON.stringify({ message: promptToSend }),
      });
      // *************************************************************************************

      const data: { message?: string } = await response.json();
      if (response.ok && data.message) {
        setMessages((prev) => [...prev, 'ü§ñ ']);

        const replyText = stripMdEmphasis(data.message);
        let i = 0;
        if (typingIntervalRef.current) clearInterval(typingIntervalRef.current);
        typingIntervalRef.current = window.setInterval(() => {
          setMessages((prev) => {
            const updated = prev.slice(0, -1);
            return [...updated, 'ü§ñ ' + replyText.slice(0, i)];
          });
          i++;
          if (i > replyText.length && typingIntervalRef.current) {
            clearInterval(typingIntervalRef.current);
            typingIntervalRef.current = null;
          }
        }, 30);

        // üîá coupe l‚Äô√©coute avant de parler
        await stopRecordingAndCleanup();

        // üîä parle et relancera le micro si le mode vocal est ON
        speak(replyText);
      } else {
        setMessages((prev) => [...prev, '‚ùå R√©ponse invalide']);
      }
    } catch (error: unknown) {
      console.error(error);
      setMessages((prev) => [...prev, '‚ö†Ô∏è Une erreur est survenue']);
    }

    setLoading(false);
  };

  // üîï coupe TTS si en cours
  const stopTTS = () => {
    try { currentAudioRef.current?.pause(); } catch { /* ignore */ }
    if (currentAudioRef.current) currentAudioRef.current.src = '';
    currentAudioRef.current = null;
    isSpeakingRef.current = false;
  };

  const speak = async (text: string) => {
    // ‚ñ∂Ô∏è le TTS ne se joue que si le mode vocal est activ√©
    if (!voiceEnabledRef.current) return;
    if (!text || !text.trim()) return;

    try {
      if (!audioUnlocked) {
        unlockAudioContext();
      }

      // stop toute lecture pr√©c√©dente
      stopTTS();

      const res = await fetch('/api/voice', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text }),
      });

      if (!res.ok) {
        console.error('Erreur API ElevenLabs:', await res.text().catch(() => ''));
        setVoiceState(voiceEnabledRef.current ? 'listening' : 'idle');
        return;
      }

      const blob = await res.blob();
      const audioUrl = URL.createObjectURL(blob);
      const audio = new Audio(audioUrl);
      currentAudioRef.current = audio;
      isSpeakingRef.current = true;
      setVoiceState('speaking');

      audio.onended = () => {
        if (currentAudioRef.current === audio) {
          currentAudioRef.current = null;
        }
        isSpeakingRef.current = false;
        URL.revokeObjectURL(audioUrl);

        // üîÅ mains libres : relance le micro automatiquement si le mode vocal est toujours ON
        if (voiceEnabledRef.current) {
          setVoiceState('listening');
          // petit d√©lai pour √©viter l‚Äôecho de fin
          setTimeout(() => {
            if (canStartRecording()) handleVoiceInput();
          }, 120);
        } else {
          setVoiceState('idle');
        }
      };

      audio.onerror = () => {
        isSpeakingRef.current = false;
        setVoiceState(voiceEnabledRef.current ? 'listening' : 'idle');
      };

      await audio.play().catch((e) => {
        // Si le navigateur bloque la lecture auto, l‚Äôutilisateur devra re-cliquer
        console.error('Lecture audio bloqu√©e/erreur:', e);
        isSpeakingRef.current = false;
        setVoiceState(voiceEnabledRef.current ? 'listening' : 'idle');
      });
    } catch (err) {
      console.error('Erreur audio :', err);
      isSpeakingRef.current = false;
      setVoiceState(voiceEnabledRef.current ? 'listening' : 'idle');
    }
  };

  // üîá Coupe le micro + lib√®re les ressources (stream, AudioContext, RAF)
  const stopRecordingAndCleanup = async () => {
    try {
      if (mediaRecorderRef.current?.state === 'recording') {
        mediaRecorderRef.current.stop();
      }
    } catch {
      // ignore
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach((t) => t.stop());
      streamRef.current = null;
    }

    if (rafIdRef.current) {
      cancelAnimationFrame(rafIdRef.current);
      rafIdRef.current = null;
    }

    if (audioCtxRef.current) {
      try {
        await audioCtxRef.current.close();
      } catch {
        // ignore
      }
      audioCtxRef.current = null;
    }

    analyserRef.current = null;
    dataArrayRef.current = null;
    userIsSpeakingRef.current = false;
    setVoiceLevel(0);
    setRecording(false);
  };

  // üé§ D√©marrage de l‚Äô√©coute ‚Üí enregistre, waveform, auto-stop quand tu as fini de parler (silence)
  const handleVoiceInput = async () => {
    if (!voiceEnabledRef.current) return;           // mode vocal OFF ‚Üí ne rien faire
    if (!canStartRecording()) return;               // pas de double d√©marrage / pas pendant TTS

    // si on (re)parle pendant TTS, on coupe la voix
    stopTTS();

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;

      // 1) MediaRecorder pour capturer l'audio (envoi √† /api/transcribe)
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      const audioChunks: Blob[] = [];
      let recordedType = mediaRecorder.mimeType || '';

      mediaRecorder.ondataavailable = (event: DataAvailableEvent) => {
        if (event.data && event.data.size > 0) {
          // @ts-ignore
          if (!recordedType && event.data?.type) recordedType = (event.data as any).type || recordedType;
          audioChunks.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        setRecording(false);
        await stopVADLoop();

        const audioBlob = new Blob(audioChunks, { type: recordedType || 'application/octet-stream' });
        const formData = new FormData();
        formData.append('audio', audioBlob);

        try {
          const res = await fetch('/api/transcribe', {
            method: 'POST',
            body: formData,
          });

          const data: { text?: string } = await res.json();
          if (data.text && data.text.trim()) {
            await handleSubmit(data.text.trim());
          } else {
            setMessages((prev) => [...prev, '‚ùå √âchec de transcription']);
            // si √©chec, rester en √©coute si mode vocal actif
            if (voiceEnabledRef.current) {
              setVoiceState('listening');
              setTimeout(() => { if (canStartRecording()) handleVoiceInput(); }, 160);
            }
          }
        } catch (err) {
          console.error('Erreur transcription', err);
          setMessages((prev) => [...prev, '‚ö†Ô∏è Erreur serveur transcription']);
          if (voiceEnabledRef.current) {
            setVoiceState('listening');
            setTimeout(() => { if (canStartRecording()) handleVoiceInput(); }, 160);
          }
        }
      };

      mediaRecorder.start();
      setRecording(true);
      setVoiceState('listening');

      // 2) D√©marrer VAD (d√©tection de voix) pour: waveform + stopper au silence
      startVADLoop(stream);
    } catch (error: any) {
      console.error('Erreur micro', error);
      alert("Erreur lors de l'acc√®s au micro.");
      setRecording(false);
      const msg = String(error?.message || error);
      if (/denied|notAllowed|NotAllowedError|Permission/i.test(msg)) {
        voiceEnabledRef.current = false;
        setVoiceState('idle');
      } else {
        setVoiceState(voiceEnabledRef.current ? 'listening' : 'idle');
      }
    }
  };

  // üß† VAD simple via WebAudio (RMS) + seuil + timeout de silence
  const startVADLoop = (stream: MediaStream) => {
    const SILENCE_HOLD_MS = 2000;
    const VOICE_THRESHOLD = 0.02;

    const AudioContextCtor =
      typeof window !== 'undefined'
        ? window.AudioContext || window.webkitAudioContext
        : undefined;

    if (!AudioContextCtor) {
      console.error('AudioContext non support√©.');
      return;
    }

    const audioCtx = new AudioContextCtor();
    audioCtxRef.current = audioCtx;

    const source = audioCtx.createMediaStreamSource(stream);
    const analyser = audioCtx.createAnalyser();
    analyser.fftSize = 2048;

    const bufferLength = analyser.fftSize;
    const dataArray = new Uint8Array(bufferLength);

    analyserRef.current = analyser;
    dataArrayRef.current = dataArray;

    source.connect(analyser);

    lastVoiceTsRef.current = performance.now();

    const tick = () => {
      analyser.getByteTimeDomainData(dataArray);

      let sumSquares = 0;
      for (let i = 0; i < dataArray.length; i++) {
        const v = (dataArray[i] - 128) / 128;
        sumSquares += v * v;
      }
      const rms = Math.sqrt(sumSquares / dataArray.length);

      setVoiceLevel(Math.min(1, rms * 6));

      const now = performance.now();
      if (rms > VOICE_THRESHOLD) {
        userIsSpeakingRef.current = true;
        lastVoiceTsRef.current = now;
      } else {
        if (userIsSpeakingRef.current && now - lastVoiceTsRef.current > SILENCE_HOLD_MS) {
          if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
            mediaRecorderRef.current.stop();
          }
          return;
        }
      }

      rafIdRef.current = requestAnimationFrame(tick);
    };

    rafIdRef.current = requestAnimationFrame(tick);
  };

  const stopVADLoop = async () => {
    if (rafIdRef.current) {
      cancelAnimationFrame(rafIdRef.current);
      rafIdRef.current = null;
    }
    if (audioCtxRef.current) {
      try {
        await audioCtxRef.current.close();
      } catch {
        // ignore
      }
      audioCtxRef.current = null;
    }
    analyserRef.current = null;
    dataArrayRef.current = null;
    userIsSpeakingRef.current = false;
    setVoiceLevel(0);

    if (streamRef.current) {
      streamRef.current.getTracks().forEach((t) => t.stop());
      streamRef.current = null;
    }
  };

  const unlockAudioContext = () => {
    if (audioUnlocked) return;

    const audio = new Audio();
    audio.src = 'data:audio/wav;base64,UklGRiQAAABXQVZFZm10IBAAAAABAAEAESsAACJWAAACABAAZGF0YQAAAAA=';
    audio.play().catch(() => {});
    setAudioUnlocked(true);
  };

  // ‚ôªÔ∏è Au montage : si un cache existe, on r√©hydrate l'UI
  useEffect(() => {
    try {
      const saved = sessionStorage.getItem("chatMessages");
      if (saved) {
        const parsed = JSON.parse(saved);
        if (Array.isArray(parsed)) setMessages(parsed);
      }
    } catch (e) {
      console.error("Erreur lecture sessionStorage:", e);
    }
  }, []);

  // üíæ √Ä chaque update : on sauvegarde en session + on scrolle en bas
  useEffect(() => {
    try {
      sessionStorage.setItem("chatMessages", JSON.stringify(messages));
    } catch (e) {
      console.error("Erreur √©criture sessionStorage:", e);
    }
    bottomRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  // === NEW: refs + trigger pour upload image ===
  const fileInputRef = useRef<HTMLInputElement | null>(null);
  const triggerImagePicker = () => fileInputRef.current?.click();

  // === NEW: handler image ‚Üí Supabase ‚Üí /api/ask ===
  const handleImagePicked = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (!file) return;

    setLoading(true); // üëà Active le spinner du bouton Envoyer

    // placeholder dans le chat
    setMessages((prev) => [...prev, 'üñºÔ∏è Envoi de la photo‚Ä¶']);

    try {
      // 1) r√©cup√©rer l'utilisateur (obligatoire pour le dossier /<uid>/ )
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) {
        alert("Tu dois √™tre connect√© pour envoyer une photo.");
        return;
      }

      // 2) upload sous /<uid>/...  (compatible avec la policy SELECT par utilisateur)
      const filePath = `${user.id}/${Date.now()}-${file.name}`;
      const { error: uploadErr } = await supabase.storage.from('photos').upload(filePath, file);
      if (uploadErr) throw uploadErr;

      // 3) URL sign√©e (bucket priv√©) ‚Äî valable 1h
      const { data: signed, error: signErr } = await supabase.storage
        .from('photos')
        .createSignedUrl(filePath, 60 * 60);
      if (signErr) throw signErr;

      const imageUrl = signed.signedUrl;

      // ‚ö†Ô∏è Remplacer le placeholder par la vraie image dans le chat
      setMessages((prev) => {
        const updated = prev.slice(0, -1); // enl√®ve "üñºÔ∏è Envoi de la photo‚Ä¶"
        return [...updated, imageUrl];      // ajoute l‚ÄôURL sign√©e ‚Üí affich√©e en <img>
      });

      // 3) /api/ask multimodal
      const { data: { session } } = await supabase.auth.getSession();

      const token = session?.access_token;

      const res = await fetch('/api/ask', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          ...(token ? { Authorization: `Bearer ${token}` } : {}),
        },
        body: JSON.stringify({
          content: [{ type: 'image_url', image_url: { url: imageUrl } }],
        }),
      });

      const data: { message?: string } = await res.json();

      if (res.ok && data.message) {
        setMessages((prev) => [...prev, 'ü§ñ ']);
        const replyText = stripMdEmphasis(data.message);
        let i = 0;
        if (typingIntervalRef.current) clearInterval(typingIntervalRef.current);
        typingIntervalRef.current = window.setInterval(() => {
          setMessages((prev) => {
            const updated = prev.slice(0, -1);
            return [...updated, 'ü§ñ ' + replyText.slice(0, i)];
          });
          i++;
          if (i > replyText.length && typingIntervalRef.current) {
            clearInterval(typingIntervalRef.current);
            typingIntervalRef.current = null;
          }
        }, 30);

        await stopRecordingAndCleanup();
        speak(replyText);
      } else {
        setMessages((prev) => [...prev, '‚ùå R√©ponse invalide (image)']);
      }
    } catch (err) {
      console.error('Upload/Analyse image', err);
      setMessages((prev) => prev.slice(0, -1));
      setMessages((prev) => [...prev, '‚ö†Ô∏è Erreur pendant l‚Äôenvoi de la photo']);
    } finally {
      if (fileInputRef.current) fileInputRef.current.value = '';
      setLoading(false); // üëà D√©sactive le spinner du bouton Envoyer
    }
  };

  const VoiceMeter = ({ level, active }: { level: number; active: boolean }) => {
    if (!active) return null;

    const width = 200;
    const height = 20;
    const points = Array.from({ length: width }, (_, i) => {
      const angle = (i / width) * Math.PI * 2;
      const y = Math.sin(angle + Date.now() / 180) * level * 6 + height / 2;
      return `${i},${y.toFixed(2)}`;
    }).join(' ');

    return (
      <svg
        viewBox={`0 0 ${width} ${height}`}
        className="absolute right-3 top-1/2 -translate-y-1/2 opacity-0 animate-fadeIn"
      >
        <polyline
          points={points}
          fill="none"
          stroke="#60A5FA"
          strokeWidth="1.2"
          strokeLinejoin="round"
          strokeLinecap="round"
        />
        <style jsx>{`
          @keyframes fadeIn {
            from {
              opacity: 0;
              transform: translateY(-50%) scaleY(0.9);
            }
            to {
              opacity: 1;
              transform: translateY(-50%) scaleY(1);
            }
          }
          .animate-fadeIn {
            animation: fadeIn 250ms ease-out forwards;
          }
        `}</style>
      </svg>
    );
  };

  // ‚ñ∂Ô∏è Bouton vocal combin√© (m√™me style exact que les autres, ic√¥ne seulement change)
  const VoiceButton = () => {
    // anti double-clic / transitions qui se chevauchent
    const transitioningRef = useRef(false);

    const onClick = async () => {
      if (transitioningRef.current) return;
      transitioningRef.current = true;
      setTimeout(() => (transitioningRef.current = false), 180);

      // toggle ON/OFF du mode vocal mains libres
      if (!voiceEnabledRef.current) {
        // ON
        voiceEnabledRef.current = true;
        unlockAudioContext();
        setVoiceState('listening');
        // d√©marre l‚Äô√©coute imm√©diate
        if (canStartRecording()) await handleVoiceInput();
      } else {
        // OFF
        voiceEnabledRef.current = false;
        setVoiceState('idle');
        stopTTS();
        await stopRecordingAndCleanup();
      }
    };

    // Ic√¥ne selon √©tat (sans changer forme/couleur/hover du bouton)
    const Icon = voiceState === 'speaking' ? Volume2 : voiceState === 'listening' ? Mic : Activity;

    return (
      <button
        onClick={onClick}
        className="h-14 w-14 bg-[#1E293B] text-[#94A3B8] hover:bg-[#334155] rounded-lg flex items-center justify-center transition"
        title="Mode vocal"
        aria-label="Mode vocal"
      >
        {voiceState === 'idle' ? (
          <span className="text-gray-400"><Icon size={22} /></span>
        ) : voiceState === 'speaking' ? (
          <span className="animate-pulse"><Icon size={22} /></span>
        ) : (
          <Icon size={22} />
        )}
      </button>
    );
  };

  return (
    <main className="flex flex-col h-screen bg-[#0F172A] text-[#F8FAFC]">
      <header className="relative text-center p-4 bg-[#0F172A] border-b border-[#1E293B]">
        <div className="flex justify-center items-center">
          <Image src="/nerion.png" alt="Nerion AI Logo" width={200} height={100} priority />
        </div>

        {/* üîò Logout ‚Äì m√™me style que les boutons du bas */}
        <button
          onClick={handleLogout}
          className="absolute right-4 top-1/2 -translate-y-1/2 h-14 w-14 rounded-lg flex items-center justify-center transition bg-[#1E293B] text-[#94A3B8] hover:bg-[#334155]"
          title="Se d√©connecter"
          aria-label="Se d√©connecter"
        >
          <LogOut size={22} />
        </button>
      </header>

      <section className="flex-1 overflow-y-auto px-4 py-6 sm:px-6">
        <div className="flex flex-col justify-end gap-4 max-w-4xl mx-auto min-h-full">
          {messages.map((msg: string, i: number) => (
            <div
              key={i}
              className="w-full bg-[#1E293B] text-[#F8FAFC] p-4 rounded-md break-words space-y-2"
            >
              {msg.startsWith("http") ? (
                <div className="flex justify-center">
                  <img
                    src={msg}
                    alt="Uploaded"
                    className="max-w-full max-h-[600px] rounded-lg object-contain border border-gray-700"
                  />
                </div>
              ) : (
                <div className="whitespace-pre-wrap break-words">{msg}</div>
              )}
            </div>
          ))}

          <div ref={bottomRef} />
        </div>
      </section>

      <footer className="px-4 py-4 sm:px-6 bg-[#0F172A] border-t border-[#1E293B]">
        <div className="w-full max-w-4xl mx-auto flex items-center gap-2">
          <div className="relative flex-grow min-w-[150px]">
            <input
              type="text"
              value={input}
              onChange={(e) => setInput(e.target.value)}
              onKeyDown={(e) => e.key === 'Enter' && handleSubmit()}
              placeholder="Pose ta question..."
              className="w-full h-14 px-4 pr-10 py-3 bg-[#1E293B] text-[#F8FAFC] text-base sm:text-lg rounded-lg placeholder-[#94A3B8] shadow-inner focus:outline-none focus:ring-2 focus:ring-[#2563EB]"
            />
            <VoiceMeter level={voiceLevel} active={recording} />
          </div>

          {/* üîò Bouton vocal combin√© ‚Äî m√™me style, ic√¥ne dynamique */}
          <VoiceButton />

          {/* === NEW: input file cach√© + bouton Upload (design only) === */}
          <input
            ref={fileInputRef}
            type="file"
            accept="image/*"
            className="hidden"
            onChange={handleImagePicked}
          />
          <button
            onClick={triggerImagePicker}
            className="h-14 w-14 bg-[#1E293B] text-[#94A3B8] hover:bg-[#334155] rounded-lg flex items-center justify-center cursor-pointer transition"
            title="Uploader une image"
            aria-label="Uploader une image"
          >
            <Upload size={22} />
          </button>

          <button
            onClick={() => handleSubmit()}
            disabled={loading}
            className="h-14 w-[120px] bg-[#2563EB] hover:bg-[#1D4ED8] text-white text-base sm:text-lg rounded-lg font-semibold transition flex items-center justify-center"
          >
            {loading ? (
              <div className="h-5 w-5 border-2 border-white border-t-transparent rounded-full animate-spin" />
            ) : (
              'Envoyer'
            )}
          </button>
        </div>
      </footer>

      {/* üîí Overlay d‚Äôauth gris√© (pas flout√©). Bloque l‚ÄôUI tant que non connect√©. */}
      {isAuthed === false && (
        <div className="fixed inset-0 z-50">
          {/* voile gris */}
          <div className="absolute inset-0 bg-black/60" />
          {/* carte centrale */}
          <div className="relative z-10 flex items-center justify-center h-full p-4">
            <div className="w-full max-w-md bg-[#0F172A]/95 border border-[#1E293B] rounded-2xl shadow-2xl p-6 text-center">
              <div className="flex justify-center mb-4">
                <Image src="/nerion.png" alt="Nerion" width={200} height={100} priority />
              </div>
              <h2 className="text-xl font-semibold mb-2">Connecte-toi pour continuer</h2>
              <p className="text-[#94A3B8] mb-5">
                Ton espace est pr√™t. Authentifie-toi avec Google pour acc√©der √† la conversation.
              </p>
              <button
                onClick={handleGoogleLogin}
                className="w-full h-12 rounded-lg bg-white/10 hover:bg.white/15 border border-[#334155] transition font-medium"
              >
                Se connecter avec Google
              </button>
            </div>
          </div>
        </div>
      )}
    </main>
  );
}
